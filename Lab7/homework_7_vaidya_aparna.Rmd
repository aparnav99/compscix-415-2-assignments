---
title: "COMPSCIX 415.2 Homework 7"
author: "Aparna Vaidya"
date: "3/13/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, warning=FALSE, message=FALSE}
library(tidyverse)
library(broom)
```

### Exercise 1

__Load the train.csv dataset into R. How many observations and columns are there?__

There are 1,460 observations and 81 columns.

```{r}
train <- read.csv("/Users/aparnavaidya/Downloads/UCB-Intro To Data Science/compscix-415-2-assignments/Lab7/train.csv")

glimpse(train)
```

### Exercise 2

__Normally at this point you would spend a few days on EDA, but for this homework we will do some very basic EDA and get right to fitting some linear regression models.__

__Our target will be SalePrice.__

__Visualize the distribution of SalePrice.__

```{r}
ggplot(data = train, mapping = aes(x = SalePrice)) + geom_histogram()
```


__Visualize the covariation between SalePrice and Neighborhood.__

```{r}
ggplot(data = train) +
  geom_count(mapping = aes(x = SalePrice, y = Neighborhood))

```


__Visualize the covariation between SalePrice and OverallQual.__

```{r}

ggplot(data = train) +
  geom_count(mapping = aes(x = SalePrice, y = OverallQual))
```

### Exercise 3

__Our target is called SalePrice. First, we can fit a simple regression model consisting of only the intercept (the average of SalePrice). Fit the model and then use the broom package to__

__take a look at the coefficient,__
__compare the coefficient to the average value of SalePrice, and__
__take a look at the R-squared.__

```{r}
(sale_lm <- lm(formula = SalePrice ~ 1, data = train))

glance(sale_lm)

mean(train$SalePrice)
```

### Exercise 4

__Now fit a linear regression model using GrLivArea, OverallQual, and Neighborhood as the features. Don’t forget to look at data_description.txt to understand what these variables mean. Ask yourself these questions before fitting the model:__

__What kind of relationship will these features have with our target?__

These features will have a positive linear relationship with the target.

__Can the relationship be estimated linearly?__

Yes. 

__Are these good features, given the problem we are trying to solve?__

Mostly yes. Because they seem to be linear, indeoendent and uncorrelated.

__After fitting the model, output the coefficients and the R-squared using the broom package.__

```{r}
(sale_lm <- lm(formula = SalePrice ~ GrLivArea + OverallQual + Neighborhood, data = train))

glance(sale_lm)
```

Answer these questions:

__How would you interpret the coefficients on GrLivArea and OverallQual?__

For every one unit increase in GrLiveArea, SalePrice would increase by $55.56. If GrLiveArea = 0, Sale Price would be -34829.24

For every one unit increase in OverallQual, SalePrice would increase by $20951.42. If OverallQual = 0, Sale Price would be -34829.24

__How would you interpret the coefficient on NeighborhoodBrkSide?__

Keeping everything else constant, house prices in NeighborhoodBrkSide will be $13025.45 less than house prices in Bloomington Heights.

__Are the features significant?__

Features are significant since they have non-zero values. 

__Are the features practically significant?__

Features are practically significant since prices can be higher or lower than the base neighborhood price.

__Is the model a good fit?__

Model is a good fit since it has a higher R squared value.

### Exercise 5 (OPTIONAL - won’t be graded)

__Feel free to play around with linear regression. Add some other features and see how the model results change.__


```{r}
(sale_lm <- lm(formula = SalePrice ~ LotConfig + Utilities, data = train))

glance(sale_lm)
```

### Exercise 6

__One downside of the linear model is that it is sensitive to unusual values because the distance incorporates a squared term. Fit a linear model to the simulated data below (use y as the target and x as the feature), and look at the resulting coefficients and R-squared. Rerun it about 5-6 times to generate different simulated datasets. What do you notice about the model’s coefficient on x and the R-squared values?__

Model's coefficient on x varies between 1.4 to 1.5. R-squared varies between 0.6 and 0.9


```{r}

sim1a <- tibble(
  x = rep(1:10, each = 3),
  y = x * 1.5 + 6 + rt(length(x), df = 2)
)

(sim1a_lm <- lm(formula = y ~ x, data = sim1a))

glance(sim1a_lm)
```

